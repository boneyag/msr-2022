{"tags": ["python", "json"], "comments": [{"score": 0, "creation_date": 1343560957, "post_id": 11699407, "comment_id": 15531083, "body": "Actually json.dumps does come with a &quot;encoding&quot; parameter, which defaults to utf-8.  Try in a python console typing help(json.dumps)"}, {"score": 0, "creation_date": 1343590850, "post_id": 11699407, "comment_id": 15536851, "body": "@JamesHurford: Yes I know, that&#39;s a parameter to tell <code>json</code> which encoding the <b><i>input</i></b> strings in the dict have. It has nothing to do with the output, and I need the <b><i>output</i></b> string to be UTF-8"}, {"score": 0, "creation_date": 1343606100, "post_id": 11699407, "comment_id": 15539608, "body": "Have a look at <a href=\"http://bit.ly/unipain\" rel=\"nofollow noreferrer\">bit.ly/unipain</a>"}], "answers": [{"comments": [{"score": 0, "creation_date": 1343465706, "post_id": 11699582, "comment_id": 15516077, "body": "Exactly the same conclusion I came to.  The only niggle I have is that simplejson is now named json, in 2.7 onwards.  So you would go import json not import simplejson as json"}, {"score": 0, "creation_date": 1343468058, "post_id": 11699582, "comment_id": 15516420, "body": "I don&#39;t understand. In my question I say that <b>I don&#39;t want ASCII</b>, yet your conclusion shows only ASCII output :P The entire point of my question was to get a unicode JSON string, yours are <i>all</i> ASCII"}, {"score": 0, "creation_date": 1343501971, "post_id": 11699582, "comment_id": 15522824, "body": "This doesn&#39;t work - try to run <code>json.dumps({&quot;Japan&quot;:&quot;\u65e5\u672c&quot;}, ensure_ascii=False)</code>. Additionally, I already stated in my question that <code>ensure_ascii</code> doesn&#39;t change the output encoding - it still tries to encode using ASCII, just without escaping non-ASCII characters first"}, {"score": 0, "creation_date": 1343608588, "post_id": 11699582, "comment_id": 15539997, "body": "+1 Yeah this works, voted you up now. If I&#39;m outputting a JSON string with millions of characters this is still a pretty wasteful solution though. I&#39;m keeping this question open for other answers"}, {"score": 0, "creation_date": 1343618785, "post_id": 11699582, "comment_id": 15541381, "body": "@Codemonkey Oh...it seems that passing the option &#39;ensure_ascii=False&#39; worked the whole time as long as you meet the requirements."}, {"score": 0, "creation_date": 1488172042, "post_id": 11699582, "comment_id": 72096632, "body": "<code>json.dumps(&quot;&#228;&quot;, ensure_ascii=False)</code> produces  <code>&quot;&#195;&#164;&quot;</code>. So the updated answer is wrong."}], "score": 7, "last_activity_date": 1343618700, "last_edit_date": 1343618700, "answer_id": 11699582, "question_id": 11699407, "body": "<h1>Requirements</h1>\n\n<ul>\n<li><p>Make sure your python files are encoded in UTF-8. Or else your non-ascii characters will become question marks, <code>?</code>. Notepad++ has excellent encoding options for this.</p></li>\n<li><p>Make sure that you have the appropriate fonts included. If you want to display Japanese characters then you need to install Japanese fonts.</p></li>\n<li><p>Make sure that your IDE supports displaying unicode characters.\nOtherwise you might get an <code>UnicodeEncodeError</code> error thrown.</p></li>\n</ul>\n\n<p>Example:</p>\n\n<pre><code>UnicodeEncodeError: 'charmap' codec can't encode characters in position 22-23: character maps to &lt;undefined&gt;\n</code></pre>\n\n<p>PyScripter works for me. It's included with \"Portable Python\" at <a href=\"http://portablepython.com/wiki/PortablePython3.2.1.1\" rel=\"nofollow\">http://portablepython.com/wiki/PortablePython3.2.1.1</a></p>\n\n<ul>\n<li>Make sure you're using Python 3+, since this version offers better unicode support.</li>\n</ul>\n\n<h1>Problem</h1>\n\n<p>json.dumps() escapes unicode characters.</p>\n\n<h1>Solution</h1>\n\n<p>Read the update at the bottom. Or...</p>\n\n<p>Replace each escaped characters with the parsed unicode character.</p>\n\n<p>I created a simple lambda function called <code>getStringWithDecodedUnicode</code> that does just that.</p>\n\n<pre><code>import re   \ngetStringWithDecodedUnicode = lambda str : re.sub( '\\\\\\\\u([\\da-f]{4})', (lambda x : chr( int( x.group(1), 16 ) )), str )\n</code></pre>\n\n<p>Here's <code>getStringWithDecodedUnicode</code> as a regular function.</p>\n\n<pre><code>def getStringWithDecodedUnicode( value ):\n    findUnicodeRE = re.compile( '\\\\\\\\u([\\da-f]{4})' )\n    def getParsedUnicode(x):\n        return chr( int( x.group(1), 16 ) )\n\n    return  findUnicodeRE.sub(getParsedUnicode, str( value ) )\n</code></pre>\n\n<h1>Example</h1>\n\n<h2>testJSONWithUnicode.py (Using PyScripter as the IDE)</h2>\n\n<pre><code>import re\nimport json\ngetStringWithDecodedUnicode = lambda str : re.sub( '\\\\\\\\u([\\da-f]{4})', (lambda x : chr( int( x.group(1), 16 ) )), str )\n\ndata = {\"Japan\":\"\u65e5\u672c\"}\njsonString = json.dumps( data )\nprint( \"json.dumps({0}) = {1}\".format( data, jsonString ) )\njsonString = getStringWithDecodedUnicode( jsonString )\nprint( \"Decoded Unicode: %s\" % jsonString )\n</code></pre>\n\n<h2>Output</h2>\n\n<pre><code>json.dumps({'Japan': '\u65e5\u672c'}) = {\"Japan\": \"\\u65e5\\u672c\"}\nDecoded Unicode: {\"Japan\": \"\u65e5\u672c\"}\n</code></pre>\n\n<h1>Update</h1>\n\n<p>Or... just pass <code>ensure_ascii=False</code> as an option for json.dumps. </p>\n\n<p>Note: You need to meet the requirements that I outlined at the beginning or else this isn't going to work.</p>\n\n<pre><code>import json\ndata = {'navn': '\u00c5ge', 'stilling': 'L\u00e6rling'}\nresult = json.dumps(d, ensure_ascii=False)\nprint( result ) # prints '{\"stilling\": \"L\u00e6rling\", \"navn\": \"\u00c5ge\"}'\n</code></pre>\n"}, {"comments": [{"score": 0, "creation_date": 1397217803, "post_id": 22247235, "comment_id": 35149619, "body": "The specs are incorrect. They mention &quot;If ensure_ascii is True (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If ensure_ascii is False, these characters will be output as-is.&quot;  But <code>json.dumps(d, ensure_ascii=False)</code> is <b>always</b> returns <code>unicode</code>-typed string."}, {"score": 1, "creation_date": 1397287825, "post_id": 22247235, "comment_id": 35178854, "body": "@avesus The spec is correct. It returns <code>unicode</code> because I used <code>from __future__ import unicode_literals</code>"}, {"score": 0, "creation_date": 1504752242, "post_id": 22247235, "comment_id": 79136095, "body": "In case of me, I used True option to use the converted string for socket.send  message_string = json_dumps(aMessageDic, ensure_ascii=True).encode(&#39;utf-8&#39;)              socket.send(message_string)"}], "score": 6, "last_activity_date": 1397285518, "last_edit_date": 1397285518, "answer_id": 22247235, "question_id": 11699407, "body": "<p><code>encode_ascii=False</code> is the best solution IMHO. </p>\n\n<p>If you are using Python2.7, here is example python file :</p>\n\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# example.py\nfrom __future__ import unicode_literals\nfrom json import dumps as json_dumps\nd = {'navn': '\u00c5ge', 'stilling': 'L\u00e6rling'}\nprint json_dumps(d, ensure_ascii=False).encode('utf-8')\n</code></pre>\n"}, {"score": 0, "last_activity_date": 1628020117, "last_edit_date": 1628020117, "answer_id": 68639383, "question_id": 11699407, "body": "<p>If on Python3.7 this is what worked for me</p>\n<pre><code>from __future__ import unicode_literals\nprint json.dumps(m,ensure_ascii=False)\n</code></pre>\n<p>Make sure <code>from __future__ import unicode_literals</code> is the first line to be imported.</p>\n"}], "is_answered": true, "answer_count": 3, "score": 8, "last_activity_date": 1628020117, "creation_date": 1343463522, "question_id": 11699407, "title": "How can I convert a dict to a unicode JSON string?", "body": "<p>This doesn't appear to be possible to me using the standard library <code>json</code> module. When using <code>json.dumps</code> it will automatically escape all non-ASCII characters then encode the string to ASCII. I can specify that it not escape non-ASCII characters, but then it crashes when it tries to convert the output to ASCII.</p>\n\n<p>The problem is - <strong>I don't want ASCII!</strong> I just want my JSON string back as a <em>unicode</em> (or <em>UTF-8</em>) string. Are there any convenient ways to do that?</p>\n\n<p>Here's an example to demonstrate what I <strong>want</strong>:</p>\n\n<pre><code>d = {'navn': '\u00c5ge', 'stilling': 'L\u00e6rling'}\njson.dumps(d, output_encoding='utf8')\n# =&gt; '{\"stilling\": \"L\u00e6rling\", \"navn\": \"\u00c5ge\"}'\n</code></pre>\n\n<p>But of course, there is no such option as <em>output_encoding</em>, so here's the actual output:</p>\n\n<pre><code>d = {'navn': '\u00c5ge', 'stilling': 'L\u00e6rling'}\njson.dumps(d)\n# =&gt; '{\"stilling\": \"L\\\\u00e6rling\", \"navn\": \"\\\\u00c5ge\"}'\n</code></pre>\n\n<p>So to summarize - I want to convert a Python dict to an <strong><em>UTF-8 JSON string</em></strong> without any escapes. How can I do that?</p>\n\n<hr>\n\n<p>I'll accept solutions like:</p>\n\n<ul>\n<li>Hacks (pre- and post processing input to <code>dumps</code> to achieve the desired effect)</li>\n<li>Subclassing the <a href=\"http://docs.python.org/library/json.html#json.JSONEncoder\" rel=\"noreferrer\">JSONEncoder</a> (I have no idea how it works and the documentation isn't very helpful)</li>\n<li>Third party libraries available on PyPi</li>\n</ul>\n"}